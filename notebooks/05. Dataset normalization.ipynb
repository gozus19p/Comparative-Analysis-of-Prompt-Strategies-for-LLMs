{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-11T08:18:42.167017Z",
     "start_time": "2024-09-11T08:18:40.294756Z"
    }
   },
   "source": [
    "%%capture\n",
    "!pip install pandas"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset normalization\n",
    "\n",
    "Here the intent is to clean up data, post-processing the output received from the LLMs.\n"
   ],
   "id": "f2a2c131a9f21e85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T08:20:28.742404Z",
     "start_time": "2024-09-11T08:20:28.735955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from os import listdir\n",
    "from os.path import join, isdir, exists\n",
    "\n",
    "resources_path: str = join(\"..\", \"resources\")\n",
    "\n",
    "MODELS: List[str] = [d for d in listdir(resources_path) if isdir(join(resources_path, d))]\n",
    "\n",
    "DATASET_PATHS: List[str] = []\n",
    "for model in MODELS:\n",
    "    DATASET_PATHS.append(f\"{resources_path}/{model}/sampled_reviews_with_output_multicall_{model}.csv\")\n",
    "    DATASET_PATHS.append(f\"{resources_path}/{model}/sampled_reviews_with_output_{model}.csv\")\n",
    "\n",
    "assert all([exists(path) for path in DATASET_PATHS]), \"All dataset must exists! Please, check\"\n",
    "\n",
    "DATASET_PATHS"
   ],
   "id": "5686816f262a2da7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../resources/gemma2_9b/sampled_reviews_with_output_multicall_gemma2_9b.csv',\n",
       " '../resources/gemma2_9b/sampled_reviews_with_output_gemma2_9b.csv',\n",
       " '../resources/qwen2_7b/sampled_reviews_with_output_multicall_qwen2_7b.csv',\n",
       " '../resources/qwen2_7b/sampled_reviews_with_output_qwen2_7b.csv',\n",
       " '../resources/llama3.1/sampled_reviews_with_output_multicall_llama3.1.csv',\n",
       " '../resources/llama3.1/sampled_reviews_with_output_llama3.1.csv',\n",
       " '../resources/phi3_medium/sampled_reviews_with_output_multicall_phi3_medium.csv',\n",
       " '../resources/phi3_medium/sampled_reviews_with_output_phi3_medium.csv',\n",
       " '../resources/mistral_7b/sampled_reviews_with_output_multicall_mistral_7b.csv',\n",
       " '../resources/mistral_7b/sampled_reviews_with_output_mistral_7b.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T08:20:37.538153Z",
     "start_time": "2024-09-11T08:20:37.058479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "sampled: pd.DataFrame = pd.read_csv(\"../resources/IMDB Dataset Sampled.csv\")\n",
    "p_indexes: List[int] = sampled[\"progressive_index\"].tolist()\n",
    "\n",
    "\n",
    "def check_for_no_case_missing(dataframe_: pd.DataFrame) -> None:\n",
    "    total_cases_count = len(dataframe_)\n",
    "    assert total_cases_count == 1000, f\"There must be 1.000 cases, but {total_cases_count}\"\n",
    "\n",
    "    missing_rows: pd.DataFrame = dataframe_[~dataframe_.progressive_index.isin(p_indexes)]\n",
    "    missing_rows_count = len(missing_rows)\n",
    "    assert missing_rows_count == 0, f\"There are missing progressive indexes {missing_rows_count}\"\n",
    "\n",
    "    not_processed: pd.DataFrame = dataframe_[dataframe_.output == \"$$$\"]\n",
    "    not_processed_count = len(not_processed)\n",
    "    assert not_processed_count == 0, f\"There are missing outputs {not_processed_count}\"\n",
    "    pass"
   ],
   "id": "ac665eaa07f6f371",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T08:20:39.338644Z",
     "start_time": "2024-09-11T08:20:39.335126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ALLOWED_COLUMNS: List[str] = [\"review\", \"sentiment\", \"entities\", \"json\", \"progressive_index\", \"output\"]\n",
    "\n",
    "\n",
    "def drop_unnecessary_columns(dataframe_: pd.DataFrame) -> pd.DataFrame:\n",
    "    columns_to_remove: List[str] = [col for col in dataframe_.columns.tolist() if col not in ALLOWED_COLUMNS]\n",
    "    dataframe_.drop(columns=columns_to_remove, inplace=True)\n",
    "    return dataframe_"
   ],
   "id": "1522bbd432abe586",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T08:22:39.927353Z",
     "start_time": "2024-09-11T08:22:39.923182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_json_output(row: pd.DataFrame) -> pd.DataFrame:\n",
    "    output: str = row[\"output\"]\n",
    "    # Removing comments in form of //\n",
    "    output = re.sub(pattern=r\"(?<!\\S)//.*?$\", flags=re.MULTILINE, string=output, repl=\"\")\n",
    "    # Extracting JSON-only\n",
    "    groups = re.findall(pattern=r\"(\\{.*})\", flags=re.DOTALL, string=output)\n",
    "    groups_count = len(groups)\n",
    "    if groups_count != 1:\n",
    "        print(f\"There must be exactly one group, but {groups_count} found: {output[:20]} [...]\")\n",
    "        row[\"json_output\"] = None\n",
    "        return row\n",
    "\n",
    "    row[\"json_output\"] = groups[0]\n",
    "    return row\n"
   ],
   "id": "2e4c3526365bc7f2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T08:22:43.102733Z",
     "start_time": "2024-09-11T08:22:40.419919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_path in DATASET_PATHS:\n",
    "    dataframe_: pd.DataFrame = pd.read_csv(dataset_path)\n",
    "    check_for_no_case_missing(dataframe_)\n",
    "    drop_unnecessary_columns(dataframe_)\n",
    "    dataframe: pd.DataFrame = dataframe_.apply(lambda row: extract_json_output(row), axis=1)\n",
    "    dataframe.to_csv(dataset_path, index=False)\n"
   ],
   "id": "f5a1605dbd284ce0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There must be exactly one group, but 0 found: This is a great anal [...]\n",
      "There must be exactly one group, but 0 found: This text appears to [...]\n",
      "There must be exactly one group, but 0 found: Based on the descrip [...]\n",
      "There must be exactly one group, but 0 found: Output: Case of diss [...]\n",
      "There must be exactly one group, but 0 found: Based on your provid [...]\n",
      "There must be exactly one group, but 0 found: Here's the analysis  [...]\n",
      "There must be exactly one group, but 0 found:  Based on the review [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  Given that there ar [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  Based on the provid [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  The review provided [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  The sentiment of th [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  The reviewer expres [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  This reviewer prais [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  {\n",
      "  \"sentiment\": \"n [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  ```json\n",
      "{\n",
      "  \"sentim [...]\n",
      "There must be exactly one group, but 0 found:  Title: Never Say Ne [...]\n",
      "There must be exactly one group, but 0 found: 1. The protagonist,  [...]\n",
      "There must be exactly one group, but 0 found:  In your review, you [...]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9d865bd19cd6baf2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
